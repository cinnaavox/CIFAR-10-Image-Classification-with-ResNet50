ğŸŒŸ CIFAR-10 Image Classification with ResNet50

Deep Learning Â· Computer Vision Â· Transfer Learning Â· TensorFlow

ğŸ§­ Ãœber dieses Projekt

Dieses Repository enthÃ¤lt zwei vollstÃ¤ndige Google-Colab-Notebooks, in denen ich den CIFAR-10-Datensatz mit Hilfe von Transfer Learning und ResNet50 klassifiziere.
Das Projekt war Teil meines Data-Analytics-Programms und hatte das Ziel, zum ersten Mal einen eigenstÃ¤ndigen Computer-Vision-Workflow aufzubauen â€“ ohne Schritt-fÃ¼r-Schritt-Anleitung.

Ich habe bewusst zwei Experimente durchgefÃ¼hrt:

Experiment A â€“ 10.000 Trainingsbilder
(gemÃ¤ÃŸ Aufgabenstellung, fÃ¼r die Live-PrÃ¤sentation)
â†’ zeigt Overfitting sehr klar

Experiment B â€“ 50.000 Trainingsbilder
(erweiterte Version zur Vertiefung)
â†’ deutlich stabilere Performance, realistischere Ergebnisse

Beide Notebooks sind im Repository enthalten.

ğŸ“‚ Repository-Inhalte
ğŸ“ cifar10-resnet50/
â”‚
â”œâ”€â”€ notebook_10k.ipynb      # Projekt gemÃ¤ÃŸ Aufgabenstellung (PrÃ¤sentation)
â”œâ”€â”€ notebook_50k.ipynb      # Erweiterte Version mit allen Trainingsdaten
â””â”€â”€ README.md

ğŸ¯ Zielsetzung

CIFAR-10 verstehen und vorbereiten

komplette Bildverarbeitungspipeline aufbauen

vortrainiertes ResNet50 nutzen (Transfer Learning)

eigenen Klassifikationskopf erstellen

zweistufiges Training umsetzen

Phase 1: nur Kopf

Phase 2: Fine-Tuning

Generalisierung & Overfitting nachvollziehbar erklÃ¤ren

Ergebnisse visualisieren (Accuracy/Loss + Beispielvorhersagen)

Unterschiede zwischen kleinem und groÃŸem Datensatz analysieren

ğŸ“¦ Der Datensatz: CIFAR-10

60.000 RGB-Bilder

10 Klassen (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)

32Ã—32 Pixel (sehr geringe AuflÃ¶sung)

50k Train / 10k Test

Die niedrige AuflÃ¶sung macht die Aufgabe Ã¼berraschend anspruchsvoll und zeigt klar, wie wichtig gute Feature-Extractor sind.

ğŸ§ª Experiment A â€“ 10.000 Trainingsbilder (Aufgabenstellung)
Vorgehen

Trainingsdaten auf 10.000 begrenzt

One-Hot-Encoding der Labels

Normalisierung der Bilder

ResNet50 (ImageNet-Weights) ohne Top-Layer

eigener Kopf: GAP â†’ Dense(256) â†’ Dense(64) â†’ Dense(10)

Phase 1: Kopf trainieren

Phase 2: ResNet auftauen + Fine-Tuning mit kleiner Lernrate

Ergebnisse

Head-Training (Phase 1)

Train Accuracy: ~0.37

Test Accuracy: ~0.36

stabile, parallele Kurven

Fine-Tuning (Phase 2)

Train Accuracy: bis 97 %

Test Accuracy: ~26.7 %

Validierungs-Loss sehr hoch

â†’ klares Overfitting

Erkenntnisse aus Experiment A

10.000 Bilder sind fÃ¼r ein Modell wie ResNet50 sehr wenig

Fine-Tuning funktioniert nur, wenn genug Daten vorhanden sind

die Trainingskurven zeigen genau das typische Verhalten von Overfitting

Beispielvorhersagen erklÃ¤ren das Muster perfekt: einige richtige Treffer, doppelt so viele falsche Zuordnungen

das Setup ist ideal, um das Thema Generalisation vs. Memorization zu verstehen

ğŸ§ª Experiment B â€“ 50.000 Trainingsbilder (Erweiterung)

Nach dem Pflichtprojekt habe ich dasselbe Setup erneut durchgefÃ¼hrt â€“ diesmal mit allen 50.000 Trainingsbildern.

Vorgehen

identische Datenvorbereitung

gleicher Kopf

identische Hyperparameter

nur mehr Trainingsdaten

Ergebnisse

Test Accuracy: 66.30 %

Training stabil und harmonisch

wesentlich bessere Generalisierung

deutlich weniger Overfitting

Fehlklassifikationen traten nur bei wirklich Ã¤hnlichen Klassen auf

Erkenntnisse aus Experiment B

Datenmenge ist ein zentraler Faktor fÃ¼r Deep Learning

Fine-Tuning wird erst dann effektiv, wenn das Modell genug Beispiele hat

ResNet50 kann auch kleine Bilder gut verarbeiten â€“ aber es braucht Masse

das Modell lernt robuste Muster, sobald genÃ¼gend Varianz vorhanden ist

ğŸ” Vergleich: 10k vs. 50k
Faktor	10k	50k
Trainingsdaten	begrenzt	komplett
Verhalten	starkes Overfitting	stabil
Test Accuracy	~26.7 %	~66.3 %
Kurven	divergierend	harmonisch
Vorhersagen	viele Fehler	deutlich besser

ğŸ‘‰ Der Unterschied ist ein perfektes Beispiel dafÃ¼r, wie sehr Daten QualitÃ¤t und StabilitÃ¤t beeinflussen.

ğŸ”§ Mein technisches Vorgehen

CIFAR-10 laden

Bilder normalisieren

Labels via One-Hot-Encoding vorbereiten

ResNet50 laden (ImageNet, ohne Kopf)

eigenen Klassifikationskopf bauen

Phase 1: Kopf trainieren

Phase 2: komplettes Modell finetunen

Evaluation via Accuracy, Loss, Plots

Beispielvorhersagen visualisieren

zweites Experiment zum Vergleich durchfÃ¼hren

ğŸ’¡ Was ich gelernt habe

Wie man Transfer Learning sinnvoll einsetzt

Warum man Modelle zuerst einfriert

Warum Fine-Tuning extrem empfindlich auf die Datenmenge reagiert

wie Overfitting aussieht â€“ nicht nur als Zahl, sondern optisch

dass Generalisierung die wichtigste Metrik ist

wie Architektur, Lernrate und Daten zusammenarbeiten

Das Projekt hat mein VerstÃ¤ndnis fÃ¼r CNNs und Deep Learning enorm vertieft.

ğŸš€ NÃ¤chste Schritte / VerbesserungsmÃ¶glichkeiten

Data Augmentation (Flip, Crop, Noise, Farbe)

Dropout & L2-Regularisierung

lÃ¤ngeres Training auf GPU/TPU

nur obere ResNet-Schichten finetunen

experimentieren mit EfficientNet oder MobileNet

Mixed Precision Training

ğŸ“« Kontakt

Bei Fragen, Feedback oder Interesse am Projekt â€“ ich freue mich Ã¼ber Austausch!
